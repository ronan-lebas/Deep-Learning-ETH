{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import CroppedImageDataset\n",
    "import torchvision.transforms.functional as F\n",
    "from FocusNet import FocusNet\n",
    "\n",
    "import os\n",
    "from torchvision import transforms\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"FocusNet_Madvanced_padding_OSGD_LR0.05_E150.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model and load weights\n",
    "model = FocusNet()\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully.\")\n",
    "# Load datasets\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = CroppedImageDataset(mode=\"advanced_padding\", split=\"train\", transform=transform)\n",
    "test_dataset = CroppedImageDataset(mode=\"advanced_padding\", split=\"test\", transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(\"DataLoaders initialized.\")\n",
    "\n",
    "def evaluate_and_display_random_images(model, dataset, num_images=6, save_dir=\"visualizations\"):\n",
    "    \"\"\"\n",
    "    Evaluate and display predictions on random images in a notebook, with proper bounding box visualization.\n",
    "    Saves the images in the specified folder.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Create directory for visualizations if it doesn't exist\n",
    "\n",
    "    # Randomly select images\n",
    "    selected_indices = random.sample(range(len(dataset)), num_images)\n",
    "\n",
    "    # Create a matplotlib grid for displaying the images\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (idx, ax) in enumerate(zip(selected_indices, axes)):\n",
    "        # Get image and ground-truth bbox\n",
    "        image, gt_bbox, id = dataset[idx]\n",
    "        gt_bbox = gt_bbox.numpy()\n",
    "\n",
    "        # Predict bbox\n",
    "        image_input = image.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        with torch.no_grad():\n",
    "            pred_bbox = model(image_input).squeeze(0).cpu().numpy()\n",
    "\n",
    "        # Scale bboxes for 124x124 visualization\n",
    "        image_size = 124\n",
    "\n",
    "        def scale_bbox(bbox):\n",
    "            cx, cy, w, h = bbox\n",
    "            xmin = (cx - w / 2) * image_size\n",
    "            ymin = (cy - h / 2) * image_size\n",
    "            xmax = (cx + w / 2) * image_size\n",
    "            ymax = (cy + h / 2) * image_size\n",
    "            return xmin, ymin, xmax, ymax\n",
    "\n",
    "        gt_xmin, gt_ymin, gt_xmax, gt_ymax = scale_bbox(gt_bbox)\n",
    "        pred_xmin, pred_ymin, pred_xmax, pred_ymax = scale_bbox(pred_bbox)\n",
    "\n",
    "        # Convert image tensor to PIL for visualization\n",
    "        pil_image = F.to_pil_image(image)\n",
    "\n",
    "        # Create the plot\n",
    "        ax.imshow(pil_image)\n",
    "        # Ground truth bbox\n",
    "        ax.add_patch(plt.Rectangle(\n",
    "            (gt_xmin, gt_ymin), gt_xmax - gt_xmin, gt_ymax - gt_ymin,\n",
    "            fill=False, edgecolor='green', linewidth=2, label=\"Ground Truth\"\n",
    "        ))\n",
    "        # Predicted bbox\n",
    "        ax.add_patch(plt.Rectangle(\n",
    "            (pred_xmin, pred_ymin), pred_xmax - pred_xmin, pred_ymax - pred_ymin,\n",
    "            fill=False, edgecolor='red', linewidth=2, label=\"Prediction\"\n",
    "        ))\n",
    "        ax.set_title(f\"Image {i+1}\\nGT: {gt_bbox}, Pred: {pred_bbox}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # Save the visualization\n",
    "        save_path = os.path.join(save_dir, f\"image_{i+1}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Saved visualization at {save_path}\")\n",
    "\n",
    "    # Adjust layout and display the grid\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on 6 random images from the train and test datasets\n",
    "print(\"Train set:\")\n",
    "evaluate_and_display_random_images(model, train_dataset, num_images=6, save_dir=\"train_visuals\")\n",
    "\n",
    "print(\"Test set:\")\n",
    "evaluate_and_display_random_images(model, test_dataset, num_images=6, save_dir=\"test_visuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import CroppedImageDataset\n",
    "import torchvision.transforms.functional as F\n",
    "from FocusNet import FocusNet\n",
    "import os\n",
    "from torchvision import transforms\n",
    "\n",
    "# Model paths and modes\n",
    "model_info = [\n",
    "    {\"path\": \"FocusNet_Mbasic_OSGD_LR0.05_E150.pth\", \"mode\": \"basic\"},\n",
    "    {\"path\": \"FocusNet_Mfiltering_OSGD_LR0.05_E150.pth\", \"mode\": \"basic\"},  # Using mode=basic for filtering test\n",
    "    {\"path\": \"FocusNet_Mbasic_padding_OSGD_LR0.05_E150.pth\", \"mode\": \"basic_padding\"},\n",
    "    {\"path\": \"FocusNet_Madvanced_padding_OSGD_LR0.05_E150.pth\", \"mode\": \"advanced_padding\"}\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load models and datasets\n",
    "models = []\n",
    "datasets = []\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = FocusNet()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "for info in model_info:\n",
    "    models.append(load_model(info[\"path\"]))\n",
    "    datasets.append(CroppedImageDataset(mode=info[\"mode\"], split=\"test\", transform=transform))\n",
    "\n",
    "print(\"All models and datasets loaded successfully.\")\n",
    "\n",
    "def scale_bbox(bbox, image_size):\n",
    "    \"\"\"Scale bounding box for visualization.\"\"\"\n",
    "    cx, cy, w, h = bbox\n",
    "    xmin = (cx - w / 2) * image_size\n",
    "    ymin = (cy - h / 2) * image_size\n",
    "    xmax = (cx + w / 2) * image_size\n",
    "    ymax = (cy + h / 2) * image_size\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "def evaluate_and_display(models, datasets, num_images=4, save_dir=\"visualizations\"):\n",
    "    \"\"\"\n",
    "    Evaluate and display predictions for all models on the same images.\n",
    "    Displays results in a 4x4 grid.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Create directory for visualizations if it doesn't exist\n",
    "\n",
    "    # Randomly select images\n",
    "    selected_indices = random.sample(range(len(datasets[0])), num_images)\n",
    "\n",
    "    # Create a matplotlib grid for displaying the images\n",
    "    fig, axes = plt.subplots(num_images, 4, figsize=(20, 15))\n",
    "\n",
    "    for row_idx, idx in enumerate(selected_indices):\n",
    "        for col_idx, (model, dataset) in enumerate(zip(models, datasets)):\n",
    "            # Get image and ground-truth bbox\n",
    "            image, gt_bbox, _ = dataset[idx]\n",
    "            gt_bbox = gt_bbox.numpy()\n",
    "\n",
    "            # Predict bbox\n",
    "            image_input = image.unsqueeze(0).to(device)  # Add batch dimension\n",
    "            with torch.no_grad():\n",
    "                pred_bbox = model(image_input).squeeze(0).cpu().numpy()\n",
    "\n",
    "            # Scale bboxes for visualization\n",
    "            image_size = 124\n",
    "            gt_xmin, gt_ymin, gt_xmax, gt_ymax = scale_bbox(gt_bbox, image_size)\n",
    "            pred_xmin, pred_ymin, pred_xmax, pred_ymax = scale_bbox(pred_bbox, image_size)\n",
    "\n",
    "            # Convert image tensor to PIL for visualization\n",
    "            pil_image = F.to_pil_image(image)\n",
    "\n",
    "            # Create the plot\n",
    "            ax = axes[row_idx, col_idx]\n",
    "            ax.imshow(pil_image)\n",
    "\n",
    "            # Ground truth bbox\n",
    "            ax.add_patch(plt.Rectangle(\n",
    "                (gt_xmin, gt_ymin), gt_xmax - gt_xmin, gt_ymax - gt_ymin,\n",
    "                fill=False, edgecolor='green', linewidth=2, label=\"Ground Truth\"\n",
    "            ))\n",
    "\n",
    "            # Predicted bbox\n",
    "            ax.add_patch(plt.Rectangle(\n",
    "                (pred_xmin, pred_ymin), pred_xmax - pred_xmin, pred_ymax - pred_ymin,\n",
    "                fill=False, edgecolor='red', linewidth=2, label=\"Prediction\"\n",
    "            ))\n",
    "\n",
    "            ax.set_title(f\"Mode: {model_info[col_idx]['mode']}\\nGT: {gt_bbox}\\nPred: {pred_bbox}\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    # Adjust layout and display the grid\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, \"comparison_grid.png\"))\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate and display\n",
    "evaluate_and_display(models, datasets, num_images=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import CroppedImageDataset\n",
    "import torchvision.transforms.functional as F\n",
    "from FocusNet import FocusNet\n",
    "from FocusNetv2 import FocusNetv2\n",
    "from FocusNetv3 import FocusNetv3\n",
    "from FocusNetv4 import FocusNetv4\n",
    "import os\n",
    "from torchvision import transforms\n",
    "\n",
    "# Model paths and modes\n",
    "model_info = [\n",
    "    {\"path\": \"FocusNet_Mbasic_padding_LL1+IOU_OSGD_LR0.065_E150.pth\", \"mode\": \"basic_padding\", \"model\": \"FocusNet\"},\n",
    "    {\"path\": \"FocusNetv2_Mbasic_padding_LL1+IOU_OSGD_LR0.065_E150.pth\", \"mode\": \"basic_padding\", \"model\": \"FocusNetv2\"},\n",
    "    {\"path\": \"FocusNetv3_Mbasic_padding_LL1+IOU_OSGD_LR0.065_E150.pth\", \"mode\": \"basic_padding\", \"model\": \"FocusNetv3\"},\n",
    "    {\"path\": \"FocusNetv4_Mbasic_padding_LL1+IOU_OSGD_LR0.065_E150.pth\", \"mode\": \"basic_padding\", \"model\": \"FocusNetv4\"},\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load models and datasets\n",
    "models = []\n",
    "datasets = []\n",
    "\n",
    "def load_model(model_path, model_name):\n",
    "    if model_name == \"FocusNet\":\n",
    "        model = FocusNet()\n",
    "    elif model_name == \"FocusNetv2\":\n",
    "        model = FocusNetv2()\n",
    "    elif model_name == \"FocusNetv3\":\n",
    "        model = FocusNetv3()\n",
    "    elif model_name == \"FocusNetv4\":\n",
    "        model = FocusNetv4()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name.\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "for info in model_info:\n",
    "    models.append(load_model(info[\"path\"], info[\"model\"]))\n",
    "    datasets.append(CroppedImageDataset(mode=info[\"mode\"], split=\"test\", transform=transform))\n",
    "\n",
    "print(\"All models and datasets loaded successfully.\")\n",
    "\n",
    "def scale_bbox(bbox, image_size):\n",
    "    \"\"\"Scale bounding box for visualization.\"\"\"\n",
    "    cx, cy, w, h = bbox\n",
    "    xmin = (cx - w / 2) * image_size\n",
    "    ymin = (cy - h / 2) * image_size\n",
    "    xmax = (cx + w / 2) * image_size\n",
    "    ymax = (cy + h / 2) * image_size\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "def evaluate_and_display(models, datasets, num_images=4, save_dir=\"visualizations\"):\n",
    "    \"\"\"\n",
    "    Evaluate and display predictions for all models on the same images.\n",
    "    Displays results in a 4x4 grid.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Create directory for visualizations if it doesn't exist\n",
    "\n",
    "    # Randomly select images\n",
    "    selected_indices = random.sample(range(len(datasets[0])), num_images)\n",
    "\n",
    "    # Create a matplotlib grid for displaying the images\n",
    "    fig, axes = plt.subplots(num_images, len(model_info), figsize=(20, 15))\n",
    "\n",
    "    for row_idx, idx in enumerate(selected_indices):\n",
    "        for col_idx, (model, dataset) in enumerate(zip(models, datasets)):\n",
    "            # Get image and ground-truth bbox\n",
    "            image, gt_bbox, _ = dataset[idx]\n",
    "            gt_bbox = gt_bbox.numpy()\n",
    "\n",
    "            # Predict bbox\n",
    "            image_input = image.unsqueeze(0).to(device)  # Add batch dimension\n",
    "            with torch.no_grad():\n",
    "                pred_bbox = model(image_input).squeeze(0).cpu().numpy()\n",
    "\n",
    "            # Scale bboxes for visualization\n",
    "            image_size = 124\n",
    "            gt_xmin, gt_ymin, gt_xmax, gt_ymax = scale_bbox(gt_bbox, image_size)\n",
    "            pred_xmin, pred_ymin, pred_xmax, pred_ymax = scale_bbox(pred_bbox, image_size)\n",
    "\n",
    "            # Convert image tensor to PIL for visualization\n",
    "            pil_image = F.to_pil_image(image)\n",
    "\n",
    "            # Create the plot\n",
    "            ax = axes[row_idx, col_idx]\n",
    "            ax.imshow(pil_image)\n",
    "\n",
    "            # Ground truth bbox\n",
    "            ax.add_patch(plt.Rectangle(\n",
    "                (gt_xmin, gt_ymin), gt_xmax - gt_xmin, gt_ymax - gt_ymin,\n",
    "                fill=False, edgecolor='green', linewidth=2, label=\"Ground Truth\"\n",
    "            ))\n",
    "\n",
    "            # Predicted bbox\n",
    "            ax.add_patch(plt.Rectangle(\n",
    "                (pred_xmin, pred_ymin), pred_xmax - pred_xmin, pred_ymax - pred_ymin,\n",
    "                fill=False, edgecolor='red', linewidth=2, label=\"Prediction\"\n",
    "            ))\n",
    "\n",
    "            ax.set_title(f\"Mode: {model_info[col_idx]['mode']}\\nGT: {gt_bbox}\\nPred: {pred_bbox}\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    # Adjust layout and display the grid\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, \"comparison_grid.png\"))\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate and display\n",
    "evaluate_and_display(models, datasets, num_images=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ETH_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
